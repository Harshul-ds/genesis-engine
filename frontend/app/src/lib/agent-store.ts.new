// src/lib/agent-store.ts
import { create } from 'zustand';
import { AppData, Step, ApiModel, PromptComponent, GeneratedPrompt, AgentStreamEvent } from './types';

// =========================================================================
// THE CORRECT PARSING LOGIC
// This is a helper function that correctly decodes the Vercel AI SDK stream format.
// =========================================================================
const parseAIStreamChunk = (chunk: string): string => {
  return chunk
    .split('\n') // A single chunk can have multiple lines
    .filter(line => line.startsWith('0:')) // We only care for the data lines
    .map(line => {
      try {
        // Remove the '0:' prefix and then JSON.parse the rest of the string
        // This correctly handles escaped characters like \" and \n
        return JSON.parse(line.substring(2));
      } catch (e) {
        return ''; // Ignore any malformed lines
      }
    })
    .join(''); // Join the clean text from all lines in the chunk
};

// ✨ NEW TYPE: To hold a prompt and its potential output
export interface FinalPromptCard {
  personaTerm: string;
  prompt: string;
  output?: string; // The output will be populated when the user clicks "Execute"
  isLoadingOutput?: boolean;
}

// Helper function to generate a prompt for a single persona
async function generateSinglePrompt(
  topic: string,
  goal: string,
  persona: string,
  model: string,
): Promise<string> {
  const response = await fetch('/api/generate-single-prompt', {
    method: 'POST',
    headers: { 'Content-Type': 'application/json' },
    body: JSON.stringify({ topic, goal, persona, model }),
  });

  if (!response.ok) {
    throw new Error('Failed to generate prompt');
  }

  const data = await response.text();
  return data;
}

// ==============================================================================
// 1. STATE DEFINITION (Adding live history)
// ==============================================================================
interface AgentState {
  // --- CORE WIZARD STATE ---
  currentStep: Step;
  isAppLoading: boolean;
  appData: AppData | null;
  agentError: string | null;

  // --- DYNAMIC DATA STATE ---
  models: ApiModel[];
  suggestedTopics: string[];

  // --- USER INPUT STATE ---
  topic: string;
  goal: string;
  selectedPersonas: string[];
  selectedModel: string;

  // --- LOADING STATE ---
  isLoadingTopics: boolean;
  isLoadingGoals: boolean;
  isLoadingPersonas: boolean;
  isGenerating: boolean;

  // --- AI-GENERATED STATE ---
  suggestedGoals: string[];
  suggestedPersonas: PromptComponent[];

  // --- OUTPUT STATE ---
  finalPrompts: FinalPromptCard[]; // Now using our new card type

  // --- NEW FOR PHASE 5 ---
  liveHistory: AgentStreamEvent[];

  // ✨ SIMPLIFIED STATE: We only need one 'thoughts' variable now.
  agentThoughts: string,
  generationResult: string,
  
  // START ADDITION 1: New state variables for the autonomous agent
  isAutonomous: boolean;
  autonomousStatus: string;
  // END ADDITION 1
}

// ==============================================================================
// 2. ACTIONS DEFINITION
// All the functions that can change the state. These are the "verbs".
// ==============================================================================
interface AgentActions {
  // --- INITIALIZATION ---
  initializeApp: (appData: AppData) => Promise<void>;

  // --- SETTERS ---
  setTopic: (topic: string) => void;
  setGoal: (goal: string) => void;
  setSelectedModel: (modelId: string) => void;

  // --- WIZARD NAVIGATION & LOGIC ---
  handleTopicSubmit: () => Promise<void>;
  handleGoalSubmit: () => Promise<void>;
  togglePersonaSelection: (personaTerm: string) => void;
  handlePersonasSubmit: () => void;
  handleModelSubmit: () => void;

  // --- MULTI-PROMPT CARD ACTIONS ---
  generatePromptCards: () => Promise<void>;
  executePromptCard: (index: number) => Promise<void>;
  
  // --- OTHER ACTIONS ---
  generateThoughts: () => Promise<void>;
  setAgentThoughts: (thoughts: string) => void;
  generateFinalPrompt: () => Promise<void>;

  reset: () => void;
  // START ADDITION 2: Orchestrator action
  runAutonomousWorkflow: (initialTopic: string) => Promise<void>;
  // END ADDITION 2
}

// ==============================================================================
// 3. STORE CREATION
// Combining state and actions into the final Zustand store.
// ==============================================================================
export const useAgentStore = create<AgentState & AgentActions>((set, get) => ({
  // --- INITIAL STATE VALUES (Adding liveHistory) ---
  currentStep: 'topic',
  isAppLoading: true,
  appData: null,
  agentError: null,
  models: [],
  suggestedTopics: [],
  topic: '',
  goal: '',
  selectedPersonas: [],
  selectedModel: '',
  isLoadingTopics: false,
  isLoadingGoals: false,
  isLoadingPersonas: false,
  isGenerating: false,
  suggestedGoals: [],
  suggestedPersonas: [],
  finalPrompts: [],
  liveHistory: [],
  agentThoughts: '',
  generationResult: '',
  // START ADDITION 1: New state defaults
  isAutonomous: false,
  autonomousStatus: '',
  // END ADDITION 1

  // --- ACTION IMPLEMENTATIONS ---

  /**
   * Initializes the application. Fetches DYNAMIC models and topic suggestions.
   */
  initializeApp: async (appData: AppData) => {
    try {
      set({ isAppLoading: true, appData, agentError: null, isLoadingTopics: true });

      const [modelsResponse, topicsResponse] = await Promise.all([
        fetch('/api/list-models'),
        fetch('/api/suggest-topics')
      ]);

      if (!modelsResponse.ok) throw new Error('Failed to fetch AI models.');
      if (!topicsResponse.ok) throw new Error('Failed to fetch initial topic suggestions.');

      const modelData: ApiModel[] = await modelsResponse.json();
      const topicData = await topicsResponse.json();

      const defaultModelId = modelData.length > 0 ? modelData[0].id : '';

      set({
        models: modelData,
        selectedModel: defaultModelId,
        suggestedTopics: topicData,
        isAppLoading: false,
        isLoadingTopics: false
      });
    } catch (error) {
      const errorMessage = error instanceof Error ? error.message : "An unknown error occurred.";
      console.error("App initialization failed:", errorMessage);
      set({
        isAppLoading: false,
        isLoadingTopics: false,
        agentError: `Could not initialize application: ${errorMessage}`,
        suggestedTopics: [
          'Sustainable fashion and eco-friendly textiles',
          'AI-powered personal finance management',
          'Remote work productivity tools',
          'Mental health and wellness apps',
          'Blockchain applications in supply chain',
          'Renewable energy storage solutions',
          'Autonomous vehicle safety systems',
          'Personalized learning platforms'
        ]
      });
    }
  },

  /**
   * Updates the topic in the state as the user types.
   */
  setTopic: (topic: string) => {
    set({ topic });
  },

  /**
   * Updates the goal in the state.
   */
  setGoal: (goal: string) => {
    set({ goal });
  },

  /**
   * Updates the user's selected model in the state.
   */
  setSelectedModel: (modelId: string) => {
    set({ selectedModel: modelId });
  },

  /**
   * Handles the submission of the topic.
   * Calls the backend to get DYNAMIC goal suggestions.
   */
  handleTopicSubmit: async () => {
    const { topic } = get();
    if (!topic.trim()) return;

    set({ isLoadingGoals: true, agentError: null, suggestedGoals: [] });

    try {
      const response = await fetch('/api/suggest-goals', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({ topic }),
      });

      if (!response.ok) {
        const errorData = await response.json();
        throw new Error(errorData.error || 'Failed to generate goals.');
      }

      const generatedGoals = await response.json();

      set({
        suggestedGoals: generatedGoals,
        isLoadingGoals: false,
        currentStep: 'goals',
        // If we're running autonomously, automatically select the first goal
        ...(get().isAutonomous ? { goal: generatedGoals[0] } : {})
      });
    } catch (error) {
      const errorMessage = error instanceof Error ? error.message : "Failed to generate goals.";
      console.error("Goal suggestion failed:", errorMessage);
      set({ isLoadingGoals: false, agentError: errorMessage });
    }
  },

  /**
   * Handles the submission of goals and moves to personas step.
   * Now uses intelligent persona suggestions based on topic and goal.
   */
  handleGoalSubmit: async () => {
    const { topic, goal, appData } = get();
    if (!goal.trim() || !appData) return;

    set({ isLoadingPersonas: true, agentError: null });

    try {
      const response = await fetch('/api/suggest-personas', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({
          topic,
          goal,
          allPersonas: appData.personas
        }),
      });

      if (!response.ok) {
        const errorData = await response.json();
        throw new Error(errorData.error || 'Failed to suggest personas.');
      }

      const suggestedPersonas = await response.json();
      
      set({
        suggestedPersonas,
        isLoadingPersonas: false,
        currentStep: 'personas',
        // If we're running autonomously, automatically select the first persona
        ...(get().isAutonomous ? { selectedPersonas: [suggestedPersonas[0].term] } : {})
      });
    } catch (error) {
      const errorMessage = error instanceof Error ? error.message : "Failed to load personas.";
      console.error("Persona suggestion failed:", errorMessage);
      set({ isLoadingPersonas: false, agentError: errorMessage });
    }
  },

  /**
   * Adds or removes a persona from the user's selection.
   */
  togglePersonaSelection: (personaTerm: string) => {
    const { selectedPersonas } = get();
    const newSelection = selectedPersonas.includes(personaTerm)
      ? selectedPersonas.filter(p => p !== personaTerm) // Remove if exists
      : [...selectedPersonas, personaTerm]; // Add if doesn't exist
    set({ selectedPersonas: newSelection });
  },

  /**
   * Finalizes the persona selection and moves to the final configuration step.
   */
  handlePersonasSubmit: () => {
    const { selectedPersonas } = get();
    if (selectedPersonas.length === 0) {
      // You could show a toast or error here, but for now we just prevent moving on.
      console.warn("No personas selected. Please select at least one.");
      return;
    }
    set({ currentStep: 'model' });
  },

  /**
   * STEP 1: GENERATE PROMPT CARDS
   * This is our new action that replaces the old generateThoughts
   */
  generatePromptCards: async () => {
    const { selectedModel, topic, goal, selectedPersonas } = get();

    // First, set loading state and clear any previous prompts
    set({ isGenerating: true, agentError: null, finalPrompts: [] });

    try {
      // Create a promise for each persona's prompt generation
      const promptPromises = selectedPersonas.map(persona =>
        generateSinglePrompt(topic, goal, persona, selectedModel)
      );

      // Wait for all prompts to be generated
      const prompts = await Promise.all(promptPromises);

      // Create the prompt cards
      const promptCards = prompts.map((prompt, index) => ({
        personaTerm: selectedPersonas[index],
        prompt,
        output: undefined,
        isLoadingOutput: false
      }));

      // Update state with the generated cards
      set({ finalPrompts: promptCards, isGenerating: false, currentStep: 'results' });

    } catch (error: any) {
      console.error('Failed to generate prompts:', error);
      set({ 
        isGenerating: false,
        agentError: error.message || 'Failed to generate prompts.',
        currentStep: 'model'
      });
    }
  },

  /**
   * Executes a prompt card and updates its output
   */
  executePromptCard: async (index: number) => {
    const { finalPrompts, selectedModel } = get();
    const card = finalPrompts[index];
    if (!card || card.isLoadingOutput) return;

    // Update loading state for this card
    set({
      finalPrompts: finalPrompts.map((c, i) => 
        i === index ? { ...c, isLoadingOutput: true } : c
      )
    });

    try {
      const response = await fetch('/api/generate', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({
          model: selectedModel,
          history: [{ role: 'user', content: card.prompt }],
        }),
      });

      if (!response.ok || !response.body) {
        throw new Error('Failed to generate output');
      }

      const reader = response.body.getReader();
      const decoder = new TextDecoder();
      let output = '';

      while (true) {
        const { done, value } = await reader.read();
        if (done) break;

        const decodedChunk = decoder.decode(value);
        const cleanText = parseAIStreamChunk(decodedChunk);
        output += cleanText;

        // Update the card's output as it streams in
        set({
          finalPrompts: finalPrompts.map((c, i) =>
            i === index ? { ...c, output } : c
          )
        });
      }

      // Update the final state of the card
      set({
        finalPrompts: finalPrompts.map((c, i) =>
          i === index ? { ...c, output, isLoadingOutput: false } : c
        )
      });

    } catch (error: any) {
      console.error('Failed to execute prompt:', error);
      
      // Update the card to show the error
      set({
        finalPrompts: finalPrompts.map((c, i) =>
          i === index ? { ...c, output: 'Error: ' + error.message, isLoadingOutput: false } : c
        ),
        agentError: error.message || 'Failed to execute prompt'
      });
    }
  },

  /**
   * STEP 1: GENERATE INITIAL THOUGHTS
   * This remains for backward compatibility
   */
  generateThoughts: async () => {
    const { selectedModel, topic, goal, selectedPersonas } = get();
    // We now go directly to the 'refinement' step, which will show the live stream.
    set({ currentStep: 'refinement', agentError: null, agentThoughts: '' });

    try {
      const thoughtsPrompt = `
        As a world-class prompt engineer, think step-by-step about how to construct the best possible prompt.
        Your task is to synthesize the perspectives of a "team" of AI personas.

        Lay out your reasoning for how you will combine their unique viewpoints to address the user's goal.
        Consider how each persona's expertise complements the others. Do NOT generate the final prompt yet.

        The user's input is:
        - Topic: "${topic}"
        - Goal: "${goal}"
        - The Team of Personas: "${selectedPersonas.join(', ')}"

        Explain:
        1. How each persona's expertise will contribute
        2. How their perspectives will be synthesized
        3. The structure you'll use to blend their insights
      `;

      const response = await fetch('/api/generate', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({
          model: selectedModel,
          history: [{ role: 'user', content: thoughtsPrompt }],
        }),
      });

      if (!response.ok || !response.body) throw new Error('API Error during thought generation.');

      const reader = response.body.getReader();
      const decoder = new TextDecoder();

      while (true) {
        const { done, value } = await reader.read();
        if (done) break; // Exit the loop when the stream is finished

        const decodedChunk = decoder.decode(value);
        const cleanText = parseAIStreamChunk(decodedChunk);

        // This updates the state with every new piece of text, triggering a live UI update.
        set((state) => ({ agentThoughts: state.agentThoughts + cleanText }));
      }

    } catch (error: any) {
      set({ agentError: error.message, currentStep: 'model' });
    }
  },

  /**
   * ✨ RENAMED ACTION: This is now clearer.
   */
  setAgentThoughts: (thoughts: string) => set({ agentThoughts: thoughts }),
  
  /**
   * STEP 2: GENERATE THE FINAL PROMPT USING THE REFINED THOUGHTS
   * This also remains for backward compatibility
   */
  generateFinalPrompt: async () => {
    const { selectedModel, topic, goal, selectedPersonas, agentThoughts } = get();
    // Go back to 'generating' for the final prompt creation
    set({ currentStep: 'generating', agentError: null, generationResult: '' });

    try {
      const finalPromptInstruction = `
        Using the following thought process as your guide:
        ---THOUGHTS---
        ${agentThoughts}
        ---
        Now, generate the final, copy-pasteable prompt in Markdown format.

        **CRITICAL INSTRUCTIONS:**
        1. **Synthesize Perspectives:** The prompt must seamlessly integrate the viewpoints of all selected personas: **${selectedPersonas.join(', ')}**.
        2. **Be Concise and Dense:** The entire prompt must be **no more than 300 words**. Focus on information density and clarity.
        3. **Address the Goal:** The prompt must be laser-focused on achieving: "${goal}" for the topic "${topic}".

        Format the prompt for maximum clarity and impact, but keep the total length under 300 words.
      `;

      const response = await fetch('/api/generate', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({
          model: selectedModel,
          history: [{ role: 'user', content: finalPromptInstruction }],
        }),
      });

      if (!response.ok || !response.body) throw new Error('API Error during final prompt generation.');

      const reader = response.body.getReader();
      const decoder = new TextDecoder();

      // Also stream the final result for a great UX
      let fullPromptResponse = '';

      while (true) {
        const { done, value } = await reader.read();
        if (done) break;
        const decodedChunk = decoder.decode(value);
        const cleanText = parseAIStreamChunk(decodedChunk);
        fullPromptResponse += cleanText;
        set((state) => ({ generationResult: state.generationResult + cleanText }));
      }

      set({ currentStep: 'results', generationResult: fullPromptResponse });

    } catch (error: any) {
      set({ agentError: error.message, currentStep: 'refinement' });
    }
  },

  /**
   * Your `handleModelSubmit`  action should now call the first step of this new process.
   */
  handleModelSubmit: async () => {
    // Preserve manual behavior: when not autonomous, just kick off the first step
    if (!get().isAutonomous) {
      // Now we use our new multi-card generation
      get().generatePromptCards();
      return;
    }

    // When running in autonomous mode, run the full flow and clean up state.
    try {
      // Generate all prompt cards
      await get().generatePromptCards();

      // Execute all prompts in sequence
      const { finalPrompts } = get();
      for (let i = 0; i < finalPrompts.length; i++) {
        await get().executePromptCard(i);
      }

      // Finalize autonomous run
      set({ currentStep: 'results', isAutonomous: false, autonomousStatus: 'Workflow Complete!' });
    } catch (error: any) {
      const errMsg = error instanceof Error ? error.message : 'Autonomous generation failed.';
      console.error('Autonomous handleModelSubmit error:', errMsg);
      set({ agentError: errMsg, isAutonomous: false });
    }
  },

  // START ADDITION 2: The new orchestrator action
  runAutonomousWorkflow: async (initialTopic: string) => {
    // Ensure we don't run it twice
    if (get().isAutonomous) return;

    // A. Kick off the process
    set({
      isAutonomous: true,
      topic: initialTopic,
      autonomousStatus: 'Initializing Agent...',
      currentStep: 'topic',
    });

    const wait = (ms: number) => new Promise(res => setTimeout(res, ms));

    try {
      // B. Select Goals - Now using dynamic suggestions
      set({ autonomousStatus: 'Determining goals...' });
      await wait(1000);
      
      // Call our dynamic goal suggestion endpoint
      await get().handleTopicSubmit();
      
      // The goals are now set in state, and if autonomous, the first goal is selected
      const suggestedGoals = get().suggestedGoals;
      if (suggestedGoals.length === 0) {
        throw new Error("No goals were suggested by the AI.");
      }

      // C. Select Persona - Now using dynamic suggestions based on topic and goal
      set({ autonomousStatus: 'Analyzing best personas...' });
      await wait(1000);
      
      // This will automatically select the top persona when autonomous
      await get().handleGoalSubmit();
      
      const selectedPersonas = get().selectedPersonas;
      if (selectedPersonas.length === 0) {
        throw new Error("No personas were suggested by the AI.");
      }
      
      // When running autonomously, select ALL suggested personas for a richer synthesis
      const suggestedPersonas = get().suggestedPersonas;
      if (suggestedPersonas.length === 0) {
        throw new Error("No personas were suggested by the AI.");
      }
      
      // Auto-select all suggested personas (up to 3) for a multi-perspective analysis
      set({ 
        selectedPersonas: suggestedPersonas.slice(0, 3).map(p => p.term),
        autonomousStatus: 'Building your expert team...'
      });
      
      // D. Select Model
      await wait(1000);
      set({
        autonomousStatus: 'Selecting optimal model...',
        selectedModel: get().models.length > 0 ? get().models[0].id : get().selectedModel,
        currentStep: 'model'
      });

      // E. Call the final generation function that already exists
      await wait(1000);
      set({ autonomousStatus: 'Preparing to generate...' });
      // This will run the generation flow and clean up isAutonomous when complete
      await get().handleModelSubmit();

    } catch (error: any) {
      console.error("Autonomous agent failed:", error);
      set({ agentError: 'The autonomous agent failed.', isAutonomous: false });
    }
  },
  // END ADDITION 2

  /**
   * Resets the entire wizard to its initial state for a new session.
   */
  reset: () => {
    set({
      currentStep: 'topic',
      topic: '',
      goal: '',
      selectedPersonas: [],
      selectedModel: '',
      suggestedGoals: [],
      suggestedPersonas: [],
      finalPrompts: [],
      agentError: null,
      liveHistory: [], // Also clear history on reset
      agentThoughts: '',
      generationResult: '',
    });
  }
}));